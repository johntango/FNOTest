{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdf76bb",
   "metadata": {},
   "source": [
    "# FNO testbed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e824542",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ff1a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "N = 256\n",
    "train_ratio = 0.8\n",
    "epochs = 500\n",
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38ea57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ----- Synthetic (x, y) Data -----\n",
    "x = np.linspace(0, 10, N)\n",
    "y = np.sin(x) + 0.1 * np.random.randn(N)\n",
    "data = np.stack([x, y], axis=1)\n",
    "\n",
    "mean = data.mean(0)\n",
    "std = data.std(0)\n",
    "data_norm = (data - mean) / std\n",
    "\n",
    "# ----- Split -----\n",
    "split = int(N * train_ratio)\n",
    "train_data = data_norm[:split]\n",
    "test_data = data_norm[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ac7da",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ----- Supervised Windowing -----\n",
    "def get_sequences(data, window=10):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - window):\n",
    "        X.append(data[i:i+window])\n",
    "        Y.append(data[i+window])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "window = 10\n",
    "X_train, Y_train = get_sequences(train_data, window)\n",
    "X_test, Y_test = get_sequences(test_data, window)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c0a8a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ----- Spectral Conv Layer (Factory Function) -----\n",
    "def spectral_conv1d(in_channels, out_channels, modes):\n",
    "    weight = torch.nn.Parameter(torch.rand(in_channels, out_channels, modes, dtype=torch.cfloat))\n",
    "\n",
    "    def layer(x):\n",
    "        B, C, L = x.shape\n",
    "        x_ft = torch.fft.rfft(x, dim=-1)\n",
    "        out_ft = torch.zeros(B, out_channels, x_ft.size(-1), dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :modes] = torch.einsum('bci,cio->bio', x_ft[:, :, :modes], weight)\n",
    "        x_out = torch.fft.irfft(out_ft, n=L, dim=-1)\n",
    "        return x_out\n",
    "\n",
    "    return layer, [weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793341d0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ----- FNO1D as Functional Module -----\n",
    "def fno1d_factory(input_dim=2, width=32, modes=16):\n",
    "    fc1_weight = torch.nn.Parameter(torch.randn(input_dim, width) * 0.1)\n",
    "    fc1_bias = torch.nn.Parameter(torch.zeros(width))\n",
    "\n",
    "    spec_layer, spec_params = spectral_conv1d(width, width, modes)\n",
    "    conv1_weight = torch.nn.Parameter(torch.randn(width, width, 1) * 0.1)\n",
    "    conv1_bias = torch.nn.Parameter(torch.zeros(width))\n",
    "\n",
    "    fc2_weight = torch.nn.Parameter(torch.randn(width, 2) * 0.1)\n",
    "    fc2_bias = torch.nn.Parameter(torch.zeros(2))\n",
    "\n",
    "    def forward(x):\n",
    "        B, T, D = x.shape\n",
    "        x = torch.matmul(x, fc1_weight) + fc1_bias  # [B, T, W]\n",
    "        x = x.permute(0, 2, 1)  # [B, W, T]\n",
    "        x1 = spec_layer(x)\n",
    "        x2 = F.conv1d(x, conv1_weight, bias=conv1_bias)\n",
    "        x = x1 + x2\n",
    "        x = x.permute(0, 2, 1)  # [B, T, W]\n",
    "        x = torch.matmul(x[:, -1], fc2_weight) + fc2_bias\n",
    "        return x\n",
    "\n",
    "    params = [fc1_weight, fc1_bias, conv1_weight, conv1_bias, fc2_weight, fc2_bias] + spec_params\n",
    "    return forward, params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e578bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ----- Model Init -----\n",
    "fno_forward, fno_params = fno1d_factory()\n",
    "optimizer = torch.optim.Adam(fno_params, lr=lr)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ----- Training Loop -----\n",
    "for epoch in range(epochs):\n",
    "    model_loss = 0.0\n",
    "    fno_forward.train = True\n",
    "    idx = torch.randperm(X_train.shape[0])\n",
    "\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        xb = X_train[idx[i:i+batch_size]]\n",
    "        yb = Y_train[idx[i:i+batch_size]]\n",
    "        pred = fno_forward(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model_loss += loss.item()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch} - Loss: {model_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57aaf6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ----- Autoregressive Inference -----\n",
    "fno_forward.train = False\n",
    "context = X_test[0:1].clone()\n",
    "preds = []\n",
    "\n",
    "for _ in range(len(Y_test)):\n",
    "    with torch.no_grad():\n",
    "        pred = fno_forward(context)\n",
    "    preds.append(pred.cpu().numpy()[0])\n",
    "    new_input = torch.cat([context[:, 1:], pred.unsqueeze(1)], dim=1)\n",
    "    context = new_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef6639",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ----- Denormalize and Plot -----\n",
    "preds = np.array(preds)\n",
    "preds_denorm = preds * std + mean\n",
    "true_denorm = Y_test.cpu().numpy() * std + mean\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(true_denorm[:, 0], true_denorm[:, 1], label='True')\n",
    "plt.plot(preds_denorm[:, 0], preds_denorm[:, 1], '--', label='Predicted')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title(\"Functional FNO Forecasting\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
